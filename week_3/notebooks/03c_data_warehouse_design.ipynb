{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 03 ¬∑ Notebook 03 ‚Äî Data Warehouse Design\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Building Analytical Foundations\n",
    "\n",
    "> Format: theory ‚Üí implementation ‚Üí best practices ‚Üí real-world application.\n",
    ">\n",
    "**Learning Objectives:**\n",
    "- Understand OLTP vs OLAP systems and when to use each\n",
    "- Master dimensional modeling (star and snowflake schemas)\n",
    "- Design and implement fact and dimension tables\n",
    "- Handle slowly changing dimensions (SCD Types 1, 2, 3)\n",
    "- Build a production-ready data mart from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ The Big Picture: Why Data Warehouses?\n",
    "\n",
    "Imagine you're Netflix:\n",
    "- **Operational System (OLTP)**: Records every play, pause, skip - millions per second\n",
    "- **Analytical System (OLAP)**: Answers \"What shows do people binge on weekends?\"\n",
    "\n",
    "You can't run heavy analytics on your operational system - it would crash! Enter the data warehouse.\n",
    "\n",
    "**Data Warehouse Benefits:**\n",
    "- üöÄ Optimized for reading and aggregation\n",
    "- üìä Historical data preservation\n",
    "- üîÑ Consistent business definitions\n",
    "- üéØ Single source of truth\n",
    "- ‚ö° Query performance at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from IPython.display import Markdown, display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization for schema diagrams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "def show_sql(query):\n",
    "    \"\"\"Pretty print SQL queries\"\"\"\n",
    "    display(Markdown(f\"```sql\\n{query}\\n```\"))\n",
    "\n",
    "print(\"‚úÖ Environment ready for warehouse design!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Part 1: OLTP vs OLAP - The Fundamental Difference\n",
    "\n",
    "Let's build the same business scenario in both paradigms to see the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating an OLTP Database (Normalized)\n",
    "\n",
    "OLTP follows normalization rules - no redundancy, referential integrity, optimized for transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OLTP database - highly normalized\n",
    "oltp_conn = sqlite3.connect('oltp_retail.db')\n",
    "oltp_cursor = oltp_conn.cursor()\n",
    "\n",
    "# Drop existing tables\n",
    "tables_to_drop = ['order_items', 'orders', 'products', 'categories', 'customers', 'addresses', 'stores']\n",
    "for table in tables_to_drop:\n",
    "    oltp_cursor.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "\n",
    "# Create normalized tables\n",
    "# Categories table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE categories (\n",
    "    category_id INTEGER PRIMARY KEY,\n",
    "    category_name TEXT NOT NULL,\n",
    "    parent_category_id INTEGER,\n",
    "    FOREIGN KEY (parent_category_id) REFERENCES categories(category_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Products table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE products (\n",
    "    product_id INTEGER PRIMARY KEY,\n",
    "    product_name TEXT NOT NULL,\n",
    "    category_id INTEGER,\n",
    "    unit_price DECIMAL(10,2),\n",
    "    unit_cost DECIMAL(10,2),\n",
    "    FOREIGN KEY (category_id) REFERENCES categories(category_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Addresses table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE addresses (\n",
    "    address_id INTEGER PRIMARY KEY,\n",
    "    street TEXT,\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    zip_code TEXT,\n",
    "    country TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Customers table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE customers (\n",
    "    customer_id INTEGER PRIMARY KEY,\n",
    "    first_name TEXT,\n",
    "    last_name TEXT,\n",
    "    email TEXT UNIQUE,\n",
    "    phone TEXT,\n",
    "    address_id INTEGER,\n",
    "    created_date DATE,\n",
    "    FOREIGN KEY (address_id) REFERENCES addresses(address_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Stores table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE stores (\n",
    "    store_id INTEGER PRIMARY KEY,\n",
    "    store_name TEXT,\n",
    "    address_id INTEGER,\n",
    "    manager_name TEXT,\n",
    "    FOREIGN KEY (address_id) REFERENCES addresses(address_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Orders table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE orders (\n",
    "    order_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER,\n",
    "    store_id INTEGER,\n",
    "    order_date DATETIME,\n",
    "    ship_date DATETIME,\n",
    "    status TEXT,\n",
    "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
    "    FOREIGN KEY (store_id) REFERENCES stores(store_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Order items table\n",
    "oltp_cursor.execute(\"\"\"\n",
    "CREATE TABLE order_items (\n",
    "    order_item_id INTEGER PRIMARY KEY,\n",
    "    order_id INTEGER,\n",
    "    product_id INTEGER,\n",
    "    quantity INTEGER,\n",
    "    unit_price DECIMAL(10,2),\n",
    "    discount DECIMAL(5,2),\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "oltp_conn.commit()\n",
    "print(\"‚úÖ OLTP schema created with 7 normalized tables\")\n",
    "print(\"\\nüìä OLTP Characteristics:\")\n",
    "print(\"  - No data redundancy\")\n",
    "print(\"  - Strong referential integrity\")\n",
    "print(\"  - Optimized for INSERT/UPDATE/DELETE\")\n",
    "print(\"  - Requires multiple JOINs for analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate OLTP database with sample data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data\n",
    "n_customers = 1000\n",
    "n_products = 200\n",
    "n_orders = 5000\n",
    "n_stores = 10\n",
    "\n",
    "# Categories\n",
    "categories = pd.DataFrame({\n",
    "    'category_id': range(1, 6),\n",
    "    'category_name': ['Electronics', 'Clothing', 'Food', 'Books', 'Sports'],\n",
    "    'parent_category_id': [None, None, None, None, None]\n",
    "})\n",
    "\n",
    "# Products\n",
    "products = pd.DataFrame({\n",
    "    'product_id': range(1, n_products + 1),\n",
    "    'product_name': [f'Product_{i}' for i in range(1, n_products + 1)],\n",
    "    'category_id': np.random.randint(1, 6, n_products),\n",
    "    'unit_price': np.round(np.random.uniform(10, 500, n_products), 2),\n",
    "    'unit_cost': np.round(np.random.uniform(5, 250, n_products), 2)\n",
    "})\n",
    "\n",
    "# Addresses\n",
    "n_addresses = n_customers + n_stores\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "states = ['NY', 'CA', 'IL', 'TX', 'AZ']\n",
    "\n",
    "addresses = pd.DataFrame({\n",
    "    'address_id': range(1, n_addresses + 1),\n",
    "    'street': [f'{np.random.randint(1, 9999)} Main St' for _ in range(n_addresses)],\n",
    "    'city': np.random.choice(cities, n_addresses),\n",
    "    'state': np.random.choice(states, n_addresses),\n",
    "    'zip_code': [f'{np.random.randint(10000, 99999)}' for _ in range(n_addresses)],\n",
    "    'country': 'USA'\n",
    "})\n",
    "\n",
    "# Customers\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'first_name': [f'First_{i}' for i in range(1, n_customers + 1)],\n",
    "    'last_name': [f'Last_{i}' for i in range(1, n_customers + 1)],\n",
    "    'email': [f'customer_{i}@email.com' for i in range(1, n_customers + 1)],\n",
    "    'phone': [f'555-{np.random.randint(1000, 9999)}' for _ in range(n_customers)],\n",
    "    'address_id': range(1, n_customers + 1),\n",
    "    'created_date': pd.date_range('2023-01-01', periods=n_customers, freq='6H').date\n",
    "})\n",
    "\n",
    "# Stores\n",
    "stores = pd.DataFrame({\n",
    "    'store_id': range(1, n_stores + 1),\n",
    "    'store_name': [f'Store_{city}_{i}' for i, city in enumerate(np.random.choice(cities, n_stores), 1)],\n",
    "    'address_id': range(n_customers + 1, n_customers + n_stores + 1),\n",
    "    'manager_name': [f'Manager_{i}' for i in range(1, n_stores + 1)]\n",
    "})\n",
    "\n",
    "# Orders\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': range(1, n_orders + 1),\n",
    "    'customer_id': np.random.randint(1, n_customers + 1, n_orders),\n",
    "    'store_id': np.random.randint(1, n_stores + 1, n_orders),\n",
    "    'order_date': pd.date_range('2024-01-01', periods=n_orders, freq='2H'),\n",
    "    'ship_date': pd.date_range('2024-01-02', periods=n_orders, freq='2H'),\n",
    "    'status': np.random.choice(['Completed', 'Pending', 'Cancelled'], n_orders, p=[0.8, 0.15, 0.05])\n",
    "})\n",
    "\n",
    "# Order items (multiple items per order)\n",
    "order_items = []\n",
    "order_item_id = 1\n",
    "for order_id in range(1, n_orders + 1):\n",
    "    n_items = np.random.randint(1, 6)  # 1-5 items per order\n",
    "    for _ in range(n_items):\n",
    "        product = products.sample(1).iloc[0]\n",
    "        order_items.append({\n",
    "            'order_item_id': order_item_id,\n",
    "            'order_id': order_id,\n",
    "            'product_id': int(product['product_id']),\n",
    "            'quantity': np.random.randint(1, 5),\n",
    "            'unit_price': float(product['unit_price']),\n",
    "            'discount': np.random.choice([0, 0.05, 0.10, 0.15], p=[0.6, 0.2, 0.15, 0.05])\n",
    "        })\n",
    "        order_item_id += 1\n",
    "\n",
    "order_items_df = pd.DataFrame(order_items)\n",
    "\n",
    "# Load data into OLTP database\n",
    "categories.to_sql('categories', oltp_conn, if_exists='append', index=False)\n",
    "products.to_sql('products', oltp_conn, if_exists='append', index=False)\n",
    "addresses.to_sql('addresses', oltp_conn, if_exists='append', index=False)\n",
    "customers.to_sql('customers', oltp_conn, if_exists='append', index=False)\n",
    "stores.to_sql('stores', oltp_conn, if_exists='append', index=False)\n",
    "orders.to_sql('orders', oltp_conn, if_exists='append', index=False)\n",
    "order_items_df.to_sql('order_items', oltp_conn, if_exists='append', index=False)\n",
    "\n",
    "print(f\"‚úÖ OLTP database populated:\")\n",
    "print(f\"  - {len(categories)} categories\")\n",
    "print(f\"  - {len(products)} products\")\n",
    "print(f\"  - {len(customers)} customers\")\n",
    "print(f\"  - {len(stores)} stores\")\n",
    "print(f\"  - {len(orders)} orders\")\n",
    "print(f\"  - {len(order_items_df)} order items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Pain of OLTP Analytics\n",
    "\n",
    "Let's try a simple business question: \"What's the total revenue by category last month?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex query needed for simple analytics in OLTP\n",
    "oltp_analytics_query = \"\"\"\n",
    "SELECT \n",
    "    c.category_name,\n",
    "    COUNT(DISTINCT o.order_id) as num_orders,\n",
    "    SUM(oi.quantity) as total_quantity,\n",
    "    SUM(oi.quantity * oi.unit_price * (1 - oi.discount)) as total_revenue\n",
    "FROM order_items oi\n",
    "JOIN orders o ON oi.order_id = o.order_id\n",
    "JOIN products p ON oi.product_id = p.product_id\n",
    "JOIN categories c ON p.category_id = c.category_id\n",
    "WHERE o.status = 'Completed'\n",
    "  AND o.order_date >= '2024-01-01'\n",
    "  AND o.order_date < '2024-02-01'\n",
    "GROUP BY c.category_name\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç OLTP Query Complexity:\")\n",
    "show_sql(oltp_analytics_query)\n",
    "\n",
    "# Execute and time it\n",
    "import time\n",
    "start = time.time()\n",
    "oltp_result = pd.read_sql(oltp_analytics_query, oltp_conn)\n",
    "oltp_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Query execution time: {oltp_time:.3f} seconds\")\n",
    "print(f\"üìä Joins required: 4\")\n",
    "print(f\"\\nResults:\")\n",
    "print(oltp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚≠ê Part 2: Star Schema - The Analytics Powerhouse\n",
    "\n",
    "Now let's redesign this for analytics using a star schema!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Understanding Star Schema Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize star schema concept\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Central fact table\n",
    "fact_box = FancyBboxPatch((0.4, 0.4), 0.2, 0.2, \n",
    "                          boxstyle=\"round,pad=0.01\",\n",
    "                          facecolor='#FF6B6B', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(fact_box)\n",
    "ax.text(0.5, 0.5, 'FACT\\nSales', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Dimension tables\n",
    "dimensions = [\n",
    "    {'name': 'DIM\\nProduct', 'pos': (0.5, 0.8), 'color': '#4ECDC4'},\n",
    "    {'name': 'DIM\\nCustomer', 'pos': (0.8, 0.6), 'color': '#4ECDC4'},\n",
    "    {'name': 'DIM\\nStore', 'pos': (0.8, 0.4), 'color': '#4ECDC4'},\n",
    "    {'name': 'DIM\\nDate', 'pos': (0.5, 0.2), 'color': '#4ECDC4'},\n",
    "    {'name': 'DIM\\nPromotion', 'pos': (0.2, 0.4), 'color': '#4ECDC4'},\n",
    "    {'name': 'DIM\\nTime', 'pos': (0.2, 0.6), 'color': '#4ECDC4'}\n",
    "]\n",
    "\n",
    "for dim in dimensions:\n",
    "    dim_box = FancyBboxPatch((dim['pos'][0]-0.08, dim['pos'][1]-0.05), 0.16, 0.1,\n",
    "                             boxstyle=\"round,pad=0.01\",\n",
    "                             facecolor=dim['color'], edgecolor='black', linewidth=1)\n",
    "    ax.add_patch(dim_box)\n",
    "    ax.text(dim['pos'][0], dim['pos'][1], dim['name'], ha='center', va='center', fontsize=11)\n",
    "    \n",
    "    # Draw connections\n",
    "    arrow = FancyArrowPatch((dim['pos'][0], dim['pos'][1]), (0.5, 0.5),\n",
    "                           connectionstyle=\"arc3,rad=0\", \n",
    "                           arrowstyle='->', \n",
    "                           linewidth=1.5, color='gray', alpha=0.5)\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Star Schema Architecture', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Add legend\n",
    "ax.text(0.5, 0.05, 'üî¥ Fact Table: Metrics & Foreign Keys | üü¢ Dimension Tables: Descriptive Attributes',\n",
    "       ha='center', fontsize=10, style='italic')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìù Star Schema Principles:\")\n",
    "print(\"1. **Fact Table**: Contains metrics (measures) and foreign keys to dimensions\")\n",
    "print(\"2. **Dimension Tables**: Contains descriptive attributes for analysis\")\n",
    "print(\"3. **Denormalized**: Trades storage for query performance\")\n",
    "print(\"4. **Single Join**: Any analysis needs only one join per dimension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Building the Star Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OLAP database with star schema\n",
    "olap_conn = sqlite3.connect('olap_retail.db')\n",
    "olap_cursor = olap_conn.cursor()\n",
    "\n",
    "# Drop existing tables\n",
    "tables_to_drop = ['fact_sales', 'dim_product', 'dim_customer', 'dim_store', 'dim_date']\n",
    "for table in tables_to_drop:\n",
    "    olap_cursor.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "\n",
    "# Create dimension tables\n",
    "# Date dimension\n",
    "olap_cursor.execute(\"\"\"\n",
    "CREATE TABLE dim_date (\n",
    "    date_key INTEGER PRIMARY KEY,\n",
    "    date DATE,\n",
    "    year INTEGER,\n",
    "    quarter INTEGER,\n",
    "    month INTEGER,\n",
    "    month_name TEXT,\n",
    "    week INTEGER,\n",
    "    day_of_month INTEGER,\n",
    "    day_of_week INTEGER,\n",
    "    day_name TEXT,\n",
    "    is_weekend INTEGER,\n",
    "    is_holiday INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Product dimension\n",
    "olap_cursor.execute(\"\"\"\n",
    "CREATE TABLE dim_product (\n",
    "    product_key INTEGER PRIMARY KEY,\n",
    "    product_id INTEGER,\n",
    "    product_name TEXT,\n",
    "    category_name TEXT,\n",
    "    brand TEXT,\n",
    "    unit_price DECIMAL(10,2),\n",
    "    unit_cost DECIMAL(10,2),\n",
    "    margin_percent DECIMAL(5,2)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Customer dimension\n",
    "olap_cursor.execute(\"\"\"\n",
    "CREATE TABLE dim_customer (\n",
    "    customer_key INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER,\n",
    "    full_name TEXT,\n",
    "    email TEXT,\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    customer_segment TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Store dimension\n",
    "olap_cursor.execute(\"\"\"\n",
    "CREATE TABLE dim_store (\n",
    "    store_key INTEGER PRIMARY KEY,\n",
    "    store_id INTEGER,\n",
    "    store_name TEXT,\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    region TEXT,\n",
    "    manager_name TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Fact table\n",
    "olap_cursor.execute(\"\"\"\n",
    "CREATE TABLE fact_sales (\n",
    "    sale_key INTEGER PRIMARY KEY,\n",
    "    date_key INTEGER,\n",
    "    product_key INTEGER,\n",
    "    customer_key INTEGER,\n",
    "    store_key INTEGER,\n",
    "    order_id INTEGER,\n",
    "    quantity INTEGER,\n",
    "    revenue DECIMAL(12,2),\n",
    "    cost DECIMAL(12,2),\n",
    "    profit DECIMAL(12,2),\n",
    "    FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
    "    FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
    "    FOREIGN KEY (customer_key) REFERENCES dim_customer(customer_key),\n",
    "    FOREIGN KEY (store_key) REFERENCES dim_store(store_key)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Create indexes\n",
    "olap_cursor.execute(\"CREATE INDEX idx_fact_date ON fact_sales(date_key)\")\n",
    "olap_cursor.execute(\"CREATE INDEX idx_fact_product ON fact_sales(product_key)\")\n",
    "olap_cursor.execute(\"CREATE INDEX idx_fact_customer ON fact_sales(customer_key)\")\n",
    "olap_cursor.execute(\"CREATE INDEX idx_fact_store ON fact_sales(store_key)\")\n",
    "\n",
    "olap_conn.commit()\n",
    "print(\"‚úÖ Star schema created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ETL: Populating the Star Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Process - Transform OLTP data to OLAP star schema\n",
    "print(\"üîÑ Starting ETL Process...\\n\")\n",
    "\n",
    "# 1. Build Date Dimension\n",
    "print(\"1Ô∏è‚É£ Building Date Dimension...\")\n",
    "start_date = pd.Timestamp('2023-01-01')\n",
    "end_date = pd.Timestamp('2025-12-31')\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "dim_date = pd.DataFrame({\n",
    "    'date_key': [int(d.strftime('%Y%m%d')) for d in date_range],\n",
    "    'date': date_range.date,\n",
    "    'year': date_range.year,\n",
    "    'quarter': date_range.quarter,\n",
    "    'month': date_range.month,\n",
    "    'month_name': date_range.strftime('%B'),\n",
    "    'week': date_range.isocalendar().week,\n",
    "    'day_of_month': date_range.day,\n",
    "    'day_of_week': date_range.dayofweek,\n",
    "    'day_name': date_range.strftime('%A'),\n",
    "    'is_weekend': (date_range.dayofweek >= 5).astype(int),\n",
    "    'is_holiday': 0\n",
    "})\n",
    "\n",
    "dim_date.to_sql('dim_date', olap_conn, if_exists='append', index=False)\n",
    "print(f\"   ‚úì Loaded {len(dim_date)} dates\")\n",
    "\n",
    "# 2. Build Product Dimension\n",
    "print(\"\\n2Ô∏è‚É£ Building Product Dimension...\")\n",
    "products_query = \"\"\"\n",
    "SELECT \n",
    "    p.product_id,\n",
    "    p.product_name,\n",
    "    c.category_name,\n",
    "    p.unit_price,\n",
    "    p.unit_cost\n",
    "FROM products p\n",
    "JOIN categories c ON p.category_id = c.category_id\n",
    "\"\"\"\n",
    "\n",
    "dim_product = pd.read_sql(products_query, oltp_conn)\n",
    "dim_product['product_key'] = range(1, len(dim_product) + 1)\n",
    "dim_product['brand'] = 'Brand_' + (dim_product['product_id'] % 5).astype(str)\n",
    "dim_product['margin_percent'] = ((dim_product['unit_price'] - dim_product['unit_cost']) / dim_product['unit_price'] * 100).round(2)\n",
    "\n",
    "dim_product.to_sql('dim_product', olap_conn, if_exists='append', index=False)\n",
    "print(f\"   ‚úì Loaded {len(dim_product)} products\")\n",
    "\n",
    "# 3. Build Customer Dimension\n",
    "print(\"\\n3Ô∏è‚É£ Building Customer Dimension...\")\n",
    "customers_query = \"\"\"\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    c.first_name || ' ' || c.last_name as full_name,\n",
    "    c.email,\n",
    "    a.city,\n",
    "    a.state\n",
    "FROM customers c\n",
    "JOIN addresses a ON c.address_id = a.address_id\n",
    "\"\"\"\n",
    "\n",
    "dim_customer = pd.read_sql(customers_query, oltp_conn)\n",
    "dim_customer['customer_key'] = range(1, len(dim_customer) + 1)\n",
    "\n",
    "# Assign customer segments randomly\n",
    "dim_customer['customer_segment'] = np.random.choice(['Bronze', 'Silver', 'Gold'], len(dim_customer), p=[0.6, 0.3, 0.1])\n",
    "\n",
    "dim_customer.to_sql('dim_customer', olap_conn, if_exists='append', index=False)\n",
    "print(f\"   ‚úì Loaded {len(dim_customer)} customers\")\n",
    "\n",
    "# 4. Build Store Dimension\n",
    "print(\"\\n4Ô∏è‚É£ Building Store Dimension...\")\n",
    "stores_query = \"\"\"\n",
    "SELECT \n",
    "    s.store_id,\n",
    "    s.store_name,\n",
    "    a.city,\n",
    "    a.state,\n",
    "    s.manager_name\n",
    "FROM stores s\n",
    "JOIN addresses a ON s.address_id = a.address_id\n",
    "\"\"\"\n",
    "\n",
    "dim_store = pd.read_sql(stores_query, oltp_conn)\n",
    "dim_store['store_key'] = range(1, len(dim_store) + 1)\n",
    "\n",
    "# Map states to regions\n",
    "region_map = {'NY': 'Northeast', 'CA': 'West', 'IL': 'Midwest', 'TX': 'South', 'AZ': 'West'}\n",
    "dim_store['region'] = dim_store['state'].map(region_map)\n",
    "\n",
    "dim_store.to_sql('dim_store', olap_conn, if_exists='append', index=False)\n",
    "print(f\"   ‚úì Loaded {len(dim_store)} stores\")\n",
    "\n",
    "print(\"\\n‚úÖ Dimension tables loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build Fact Table\n",
    "print(\"5Ô∏è‚É£ Building Fact Table...\\n\")\n",
    "\n",
    "# Extract order details from OLTP\n",
    "fact_query = \"\"\"\n",
    "SELECT \n",
    "    oi.order_item_id,\n",
    "    o.order_id,\n",
    "    o.order_date,\n",
    "    oi.product_id,\n",
    "    o.customer_id,\n",
    "    o.store_id,\n",
    "    oi.quantity,\n",
    "    oi.unit_price,\n",
    "    oi.discount,\n",
    "    p.unit_cost\n",
    "FROM order_items oi\n",
    "JOIN orders o ON oi.order_id = o.order_id\n",
    "JOIN products p ON oi.product_id = p.product_id\n",
    "WHERE o.status = 'Completed'\n",
    "\"\"\"\n",
    "\n",
    "fact_data = pd.read_sql(fact_query, oltp_conn)\n",
    "\n",
    "# Create lookups for dimension keys\n",
    "product_lookup = dim_product.set_index('product_id')['product_key'].to_dict()\n",
    "customer_lookup = dim_customer.set_index('customer_id')['customer_key'].to_dict()\n",
    "store_lookup = dim_store.set_index('store_id')['store_key'].to_dict()\n",
    "\n",
    "# Transform to fact table structure\n",
    "fact_sales = pd.DataFrame()\n",
    "fact_sales['sale_key'] = range(1, len(fact_data) + 1)\n",
    "\n",
    "# Date key transformation\n",
    "fact_sales['date_key'] = pd.to_datetime(fact_data['order_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# Dimension keys\n",
    "fact_sales['product_key'] = fact_data['product_id'].map(product_lookup)\n",
    "fact_sales['customer_key'] = fact_data['customer_id'].map(customer_lookup)\n",
    "fact_sales['store_key'] = fact_data['store_id'].map(store_lookup)\n",
    "\n",
    "# Measures\n",
    "fact_sales['order_id'] = fact_data['order_id']\n",
    "fact_sales['quantity'] = fact_data['quantity']\n",
    "fact_sales['revenue'] = fact_data['quantity'] * fact_data['unit_price'] * (1 - fact_data['discount'])\n",
    "fact_sales['cost'] = fact_data['quantity'] * fact_data['unit_cost']\n",
    "fact_sales['profit'] = fact_sales['revenue'] - fact_sales['cost']\n",
    "\n",
    "# Remove any rows with null keys\n",
    "fact_sales = fact_sales.dropna()\n",
    "\n",
    "# Load to OLAP database\n",
    "fact_sales.to_sql('fact_sales', olap_conn, if_exists='append', index=False)\n",
    "\n",
    "print(f\"‚úì Loaded {len(fact_sales):,} fact records\")\n",
    "print(f\"‚úì Total revenue: ${fact_sales['revenue'].sum():,.2f}\")\n",
    "print(f\"‚úì Total profit: ${fact_sales['profit'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ ETL Process Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 The Power of Star Schema Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same business question with star schema\n",
    "star_analytics_query = \"\"\"\n",
    "SELECT \n",
    "    p.category_name,\n",
    "    COUNT(DISTINCT f.order_id) as num_orders,\n",
    "    SUM(f.quantity) as total_quantity,\n",
    "    SUM(f.revenue) as total_revenue,\n",
    "    SUM(f.profit) as total_profit\n",
    "FROM fact_sales f\n",
    "JOIN dim_product p ON f.product_key = p.product_key\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "WHERE d.year = 2024 \n",
    "  AND d.month = 1\n",
    "GROUP BY p.category_name\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚≠ê Star Schema Query Simplicity:\")\n",
    "show_sql(star_analytics_query)\n",
    "\n",
    "# Execute and time it\n",
    "start = time.time()\n",
    "star_result = pd.read_sql(star_analytics_query, olap_conn)\n",
    "star_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Query execution time: {star_time:.3f} seconds\")\n",
    "print(f\"üìä Joins required: 2 (only what we need!)\")\n",
    "print(f\"\\nResults:\")\n",
    "print(star_result)\n",
    "\n",
    "# Compare performance\n",
    "if oltp_time > 0:\n",
    "    print(f\"\\nüöÄ Performance Improvement: {(oltp_time/star_time):.1f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Part 3: Slowly Changing Dimensions (SCD)\n",
    "\n",
    "Real world data changes! How do we handle this in our warehouse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate SCD Types\n",
    "print(\"üîÑ Slowly Changing Dimensions (SCD) Types\\n\")\n",
    "print(\"Scenario: Customer 'John Doe' moves from New York to California\\n\")\n",
    "\n",
    "# Original customer record\n",
    "original = pd.DataFrame({\n",
    "    'customer_key': [1],\n",
    "    'customer_id': [1001],\n",
    "    'name': ['John Doe'],\n",
    "    'city': ['New York'],\n",
    "    'state': ['NY']\n",
    "})\n",
    "\n",
    "print(\"Original Record:\")\n",
    "print(original)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Type 1: Overwrite\n",
    "print(\"üìù SCD Type 1: Overwrite\")\n",
    "scd1 = original.copy()\n",
    "scd1['city'] = 'Los Angeles'\n",
    "scd1['state'] = 'CA'\n",
    "print(scd1)\n",
    "print(\"‚úÖ Simple | ‚ùå Lost history\\n\")\n",
    "\n",
    "# Type 2: Add new row\n",
    "print(\"üìù SCD Type 2: Add New Row\")\n",
    "scd2 = pd.DataFrame({\n",
    "    'customer_key': [1, 2],\n",
    "    'customer_id': [1001, 1001],\n",
    "    'name': ['John Doe', 'John Doe'],\n",
    "    'city': ['New York', 'Los Angeles'],\n",
    "    'state': ['NY', 'CA'],\n",
    "    'effective_date': ['2023-01-01', '2024-06-01'],\n",
    "    'is_current': [0, 1]\n",
    "})\n",
    "print(scd2)\n",
    "print(\"‚úÖ Full history | ‚ùå Complex queries\\n\")\n",
    "\n",
    "# Type 3: Add column\n",
    "print(\"üìù SCD Type 3: Add Column\")\n",
    "scd3 = original.copy()\n",
    "scd3['current_city'] = 'Los Angeles'\n",
    "scd3['previous_city'] = 'New York'\n",
    "print(scd3[['customer_key', 'name', 'current_city', 'previous_city']])\n",
    "print(\"‚úÖ Track current & previous | ‚ùå Only one change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Practice Exercise\n",
    "\n",
    "Design your own star schema for a streaming service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a star schema for Netflix-like service\n",
    "# Think about:\n",
    "# - Fact grain: viewing sessions\n",
    "# - Dimensions: user, content, device, time\n",
    "# - Measures: watch_time, completion_rate\n",
    "\n",
    "print(\"Your turn! Design a streaming service star schema\")\n",
    "print(\"\\nHint: Consider these dimensions:\")\n",
    "print(\"- dim_user (user_id, age_group, subscription_type)\")\n",
    "print(\"- dim_content (movie_id, title, genre, rating)\")\n",
    "print(\"- dim_device (device_type, platform)\")\n",
    "print(\"- dim_date (standard date dimension)\")\n",
    "print(\"\\nAnd fact table:\")\n",
    "print(\"- fact_views (watch_duration, completion_pct, quality)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "1. **OLTP vs OLAP**: Different designs for different purposes\n",
    "2. **Star Schema**: Simple, fast, business-friendly\n",
    "3. **ETL Process**: Transform normalized to dimensional\n",
    "4. **SCD Types**: Handle changing data appropriately\n",
    "5. **Performance**: Proper design = faster queries\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Next notebook: Advanced SQL Analytics with window functions!\n",
    "\n",
    "Remember: **Good warehouse design is the foundation of analytics!** üèóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "oltp_conn.close()\n",
    "olap_conn.close()\n",
    "print(\"‚úÖ Connections closed. Great work!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
