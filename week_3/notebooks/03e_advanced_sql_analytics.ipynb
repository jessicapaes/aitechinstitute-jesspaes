{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 03 ¬∑ Notebook 06 ‚Äî Advanced SQL Analytics\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master the Art of Complex Analytical Queries\n",
    "\n",
    "> Format: theory ‚Üí implementation ‚Üí best practices ‚Üí real-world application.\n",
    ">\n",
    "**Learning Objectives:**\n",
    "- Master window functions for advanced analytics\n",
    "- Build complex queries with Common Table Expressions (CTEs)\n",
    "- Implement recursive queries for hierarchical data\n",
    "- Perform pivoting and unpivoting operations\n",
    "- Optimize complex analytical queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ The Analytics Challenge\n",
    "\n",
    "You're the Senior Data Analyst at an e-commerce company. The CEO wants:\n",
    "1. **Customer cohort retention analysis**\n",
    "2. **Product sales rankings with trends**\n",
    "3. **Employee hierarchy reports**\n",
    "4. **Time-series analysis with moving averages**\n",
    "\n",
    "Simple GROUP BY won't cut it. Time for **advanced SQL**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure displays\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def show_sql(query, title=\"SQL Query:\"):\n",
    "    \"\"\"Pretty print SQL queries\"\"\"\n",
    "    print(f\"\\nüìù {title}\")\n",
    "    display(Markdown(f\"```sql\\n{query}\\n```\"))\n",
    "\n",
    "def run_query(query, conn, title=\"Results:\"):\n",
    "    \"\"\"Execute query and display results\"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    print(f\"\\nüìä {title}\")\n",
    "    display(result)\n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Environment ready for advanced SQL analytics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Setting Up Our Analytics Database\n",
    "\n",
    "We'll create a comprehensive e-commerce database with sales, customers, products, and employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "conn = sqlite3.connect('analytics.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop existing tables\n",
    "tables = ['sales', 'customers', 'products', 'employees', 'categories']\n",
    "for table in tables:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "\n",
    "# Create tables\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE customers (\n",
    "    customer_id INTEGER PRIMARY KEY,\n",
    "    customer_name TEXT,\n",
    "    signup_date DATE,\n",
    "    country TEXT,\n",
    "    customer_segment TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE products (\n",
    "    product_id INTEGER PRIMARY KEY,\n",
    "    product_name TEXT,\n",
    "    category TEXT,\n",
    "    price DECIMAL(10,2),\n",
    "    launch_date DATE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE sales (\n",
    "    sale_id INTEGER PRIMARY KEY,\n",
    "    sale_date DATE,\n",
    "    customer_id INTEGER,\n",
    "    product_id INTEGER,\n",
    "    quantity INTEGER,\n",
    "    revenue DECIMAL(10,2),\n",
    "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE employees (\n",
    "    employee_id INTEGER PRIMARY KEY,\n",
    "    employee_name TEXT,\n",
    "    manager_id INTEGER,\n",
    "    department TEXT,\n",
    "    salary DECIMAL(10,2),\n",
    "    hire_date DATE,\n",
    "    FOREIGN KEY (manager_id) REFERENCES employees(employee_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE categories (\n",
    "    category_id INTEGER PRIMARY KEY,\n",
    "    category_name TEXT,\n",
    "    parent_category_id INTEGER,\n",
    "    FOREIGN KEY (parent_category_id) REFERENCES categories(category_id)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"‚úÖ Database schema created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Customers\n",
    "n_customers = 1000\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'customer_name': [f'Customer_{i}' for i in range(1, n_customers + 1)],\n",
    "    'signup_date': pd.date_range('2022-01-01', periods=n_customers, freq='6H').date,\n",
    "    'country': np.random.choice(['USA', 'UK', 'Germany', 'France', 'Japan'], n_customers),\n",
    "    'customer_segment': np.random.choice(['Premium', 'Standard', 'Basic'], n_customers, p=[0.2, 0.5, 0.3])\n",
    "})\n",
    "\n",
    "# Products\n",
    "n_products = 100\n",
    "categories = ['Electronics', 'Clothing', 'Books', 'Home', 'Sports']\n",
    "products = pd.DataFrame({\n",
    "    'product_id': range(1, n_products + 1),\n",
    "    'product_name': [f'Product_{i}' for i in range(1, n_products + 1)],\n",
    "    'category': np.random.choice(categories, n_products),\n",
    "    'price': np.round(np.random.uniform(10, 500, n_products), 2),\n",
    "    'launch_date': pd.date_range('2021-01-01', periods=n_products, freq='3D').date\n",
    "})\n",
    "\n",
    "# Sales (multiple purchases per customer)\n",
    "n_sales = 20000\n",
    "sales_dates = pd.date_range('2022-01-01', '2024-12-31', freq='H')\n",
    "sales = pd.DataFrame({\n",
    "    'sale_id': range(1, n_sales + 1),\n",
    "    'sale_date': np.random.choice(sales_dates, n_sales).date,\n",
    "    'customer_id': np.random.randint(1, n_customers + 1, n_sales),\n",
    "    'product_id': np.random.randint(1, n_products + 1, n_sales),\n",
    "    'quantity': np.random.randint(1, 5, n_sales)\n",
    "})\n",
    "\n",
    "# Calculate revenue based on product prices\n",
    "sales = sales.merge(products[['product_id', 'price']], on='product_id')\n",
    "sales['revenue'] = sales['quantity'] * sales['price']\n",
    "sales = sales.drop('price', axis=1)\n",
    "\n",
    "# Employees with hierarchy\n",
    "employees = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    'employee_name': ['CEO', 'CTO', 'CFO', 'VP_Eng', 'VP_Sales', 'VP_Finance',\n",
    "                      'Eng_Lead1', 'Eng_Lead2', 'Sales_Lead1', 'Sales_Lead2',\n",
    "                      'Engineer1', 'Engineer2', 'Engineer3', 'Sales_Rep1', 'Sales_Rep2'],\n",
    "    'manager_id': [None, 1, 1, 2, 2, 3, 4, 4, 5, 5, 7, 7, 8, 9, 10],\n",
    "    'department': ['Executive', 'Technology', 'Finance', 'Engineering', 'Sales', 'Finance',\n",
    "                  'Engineering', 'Engineering', 'Sales', 'Sales',\n",
    "                  'Engineering', 'Engineering', 'Engineering', 'Sales', 'Sales'],\n",
    "    'salary': [500000, 350000, 350000, 250000, 250000, 200000,\n",
    "              180000, 180000, 150000, 150000,\n",
    "              120000, 120000, 110000, 90000, 85000],\n",
    "    'hire_date': pd.date_range('2020-01-01', periods=15, freq='2M').date\n",
    "})\n",
    "\n",
    "# Category hierarchy\n",
    "categories_df = pd.DataFrame({\n",
    "    'category_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'category_name': ['All Products', 'Electronics', 'Clothing', 'Home',\n",
    "                     'Computers', 'Audio', 'Men', 'Women', 'Kitchen', 'Furniture'],\n",
    "    'parent_category_id': [None, 1, 1, 1, 2, 2, 3, 3, 4, 4]\n",
    "})\n",
    "\n",
    "# Load data into database\n",
    "customers.to_sql('customers', conn, if_exists='append', index=False)\n",
    "products.to_sql('products', conn, if_exists='append', index=False)\n",
    "sales.to_sql('sales', conn, if_exists='append', index=False)\n",
    "employees.to_sql('employees', conn, if_exists='append', index=False)\n",
    "categories_df.to_sql('categories', conn, if_exists='append', index=False)\n",
    "\n",
    "print(f\"‚úÖ Loaded data:\")\n",
    "print(f\"  - {len(customers):,} customers\")\n",
    "print(f\"  - {len(products):,} products\")\n",
    "print(f\"  - {len(sales):,} sales transactions\")\n",
    "print(f\"  - {len(employees):,} employees\")\n",
    "print(f\"  - {len(categories_df):,} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü™ü Part 1: Window Functions - Analytics Without Grouping\n",
    "\n",
    "Window functions are SQL's superpower for complex analytics. They calculate across rows while keeping all row details!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Ranking Functions\n",
    "\n",
    "ROW_NUMBER(), RANK(), DENSE_RANK(), NTILE() - each has its purpose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different ranking functions\n",
    "ranking_query = \"\"\"\n",
    "WITH product_sales AS (\n",
    "    SELECT \n",
    "        p.product_name,\n",
    "        p.category,\n",
    "        SUM(s.revenue) as total_revenue\n",
    "    FROM sales s\n",
    "    JOIN products p ON s.product_id = p.product_id\n",
    "    GROUP BY p.product_id, p.product_name, p.category\n",
    ")\n",
    "SELECT \n",
    "    category,\n",
    "    product_name,\n",
    "    total_revenue,\n",
    "    ROW_NUMBER() OVER (PARTITION BY category ORDER BY total_revenue DESC) as row_num,\n",
    "    RANK() OVER (PARTITION BY category ORDER BY total_revenue DESC) as rank,\n",
    "    DENSE_RANK() OVER (PARTITION BY category ORDER BY total_revenue DESC) as dense_rank,\n",
    "    NTILE(4) OVER (PARTITION BY category ORDER BY total_revenue DESC) as quartile\n",
    "FROM product_sales\n",
    "ORDER BY category, total_revenue DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "show_sql(ranking_query, \"Ranking Functions Comparison\")\n",
    "ranking_result = run_query(ranking_query, conn, \"Different ranking methods:\")\n",
    "\n",
    "print(\"\\nüí° Key Differences:\")\n",
    "print(\"- ROW_NUMBER: Always unique (1,2,3,4...)\")\n",
    "print(\"- RANK: Ties get same rank, gaps after (1,2,2,4...)\")\n",
    "print(\"- DENSE_RANK: Ties get same rank, no gaps (1,2,2,3...)\")\n",
    "print(\"- NTILE: Divides into equal buckets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Top-N Per Group Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 3 products in each category\n",
    "top_n_query = \"\"\"\n",
    "WITH ranked_products AS (\n",
    "    SELECT \n",
    "        p.category,\n",
    "        p.product_name,\n",
    "        SUM(s.revenue) as total_revenue,\n",
    "        COUNT(DISTINCT s.customer_id) as unique_customers,\n",
    "        RANK() OVER (\n",
    "            PARTITION BY p.category \n",
    "            ORDER BY SUM(s.revenue) DESC\n",
    "        ) as revenue_rank\n",
    "    FROM sales s\n",
    "    JOIN products p ON s.product_id = p.product_id\n",
    "    GROUP BY p.product_id, p.product_name, p.category\n",
    ")\n",
    "SELECT \n",
    "    category,\n",
    "    product_name,\n",
    "    total_revenue,\n",
    "    unique_customers,\n",
    "    revenue_rank\n",
    "FROM ranked_products\n",
    "WHERE revenue_rank <= 3\n",
    "ORDER BY category, revenue_rank\n",
    "\"\"\"\n",
    "\n",
    "show_sql(top_n_query, \"Top-N Per Group\")\n",
    "top_n_result = run_query(top_n_query, conn, \"Top 3 products per category:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Running Totals and Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate running totals and moving averages\n",
    "time_series_query = \"\"\"\n",
    "WITH daily_sales AS (\n",
    "    SELECT \n",
    "        sale_date,\n",
    "        SUM(revenue) as daily_revenue,\n",
    "        COUNT(DISTINCT customer_id) as daily_customers\n",
    "    FROM sales\n",
    "    WHERE sale_date >= '2024-01-01' \n",
    "      AND sale_date <= '2024-01-31'\n",
    "    GROUP BY sale_date\n",
    ")\n",
    "SELECT \n",
    "    sale_date,\n",
    "    daily_revenue,\n",
    "    daily_customers,\n",
    "    -- Running total\n",
    "    SUM(daily_revenue) OVER (\n",
    "        ORDER BY sale_date \n",
    "        ROWS UNBOUNDED PRECEDING\n",
    "    ) as cumulative_revenue,\n",
    "    -- 7-day moving average\n",
    "    AVG(daily_revenue) OVER (\n",
    "        ORDER BY sale_date \n",
    "        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "    ) as moving_avg_7d,\n",
    "    -- Month-to-date average\n",
    "    AVG(daily_revenue) OVER (\n",
    "        ORDER BY sale_date\n",
    "        ROWS UNBOUNDED PRECEDING\n",
    "    ) as mtd_avg_revenue\n",
    "FROM daily_sales\n",
    "ORDER BY sale_date\n",
    "\"\"\"\n",
    "\n",
    "show_sql(time_series_query, \"Time Series Analytics\")\n",
    "time_series_result = run_query(time_series_query, conn, \"Daily sales with running metrics:\")\n",
    "\n",
    "# Visualize the results\n",
    "if len(time_series_result) > 0:\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    ax1.plot(pd.to_datetime(time_series_result['sale_date']), \n",
    "             time_series_result['daily_revenue'], \n",
    "             label='Daily Revenue', marker='o', markersize=3)\n",
    "    ax1.plot(pd.to_datetime(time_series_result['sale_date']), \n",
    "             time_series_result['moving_avg_7d'], \n",
    "             label='7-Day Moving Avg', linewidth=2)\n",
    "    ax1.set_title('Daily Revenue with Moving Average')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(pd.to_datetime(time_series_result['sale_date']), \n",
    "             time_series_result['cumulative_revenue'], \n",
    "             label='Cumulative Revenue', color='green', linewidth=2)\n",
    "    ax2.set_title('Cumulative Revenue (Month-to-Date)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 LAG and LEAD - Time Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with previous period using LAG\n",
    "lag_lead_query = \"\"\"\n",
    "WITH monthly_sales AS (\n",
    "    SELECT \n",
    "        strftime('%Y-%m', sale_date) as month,\n",
    "        SUM(revenue) as monthly_revenue,\n",
    "        COUNT(DISTINCT customer_id) as monthly_customers\n",
    "    FROM sales\n",
    "    WHERE sale_date >= '2024-01-01'\n",
    "    GROUP BY strftime('%Y-%m', sale_date)\n",
    ")\n",
    "SELECT \n",
    "    month,\n",
    "    monthly_revenue,\n",
    "    monthly_customers,\n",
    "    -- Previous month\n",
    "    LAG(monthly_revenue, 1) OVER (ORDER BY month) as prev_month_revenue,\n",
    "    -- Month-over-month change\n",
    "    monthly_revenue - LAG(monthly_revenue, 1) OVER (ORDER BY month) as mom_change,\n",
    "    -- Month-over-month percentage\n",
    "    ROUND(\n",
    "        (monthly_revenue - LAG(monthly_revenue, 1) OVER (ORDER BY month)) * 100.0 / \n",
    "        NULLIF(LAG(monthly_revenue, 1) OVER (ORDER BY month), 0), \n",
    "        2\n",
    "    ) as mom_change_pct,\n",
    "    -- Next month (for forecasting)\n",
    "    LEAD(monthly_revenue, 1) OVER (ORDER BY month) as next_month_revenue\n",
    "FROM monthly_sales\n",
    "ORDER BY month\n",
    "LIMIT 12\n",
    "\"\"\"\n",
    "\n",
    "show_sql(lag_lead_query, \"LAG/LEAD for Time Comparisons\")\n",
    "lag_lead_result = run_query(lag_lead_query, conn, \"Month-over-month analysis:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Part 2: Common Table Expressions (CTEs)\n",
    "\n",
    "CTEs make complex queries readable and maintainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Multi-Step Analysis with CTEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex cohort retention analysis using multiple CTEs\n",
    "cohort_query = \"\"\"\n",
    "WITH \n",
    "-- Step 1: Identify first purchase date for each customer\n",
    "customer_cohorts AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        MIN(sale_date) as first_purchase_date,\n",
    "        strftime('%Y-%m', MIN(sale_date)) as cohort_month\n",
    "    FROM sales\n",
    "    GROUP BY customer_id\n",
    "),\n",
    "-- Step 2: Calculate months since first purchase\n",
    "customer_purchases AS (\n",
    "    SELECT \n",
    "        s.customer_id,\n",
    "        c.cohort_month,\n",
    "        strftime('%Y-%m', s.sale_date) as purchase_month,\n",
    "        (strftime('%Y', s.sale_date) - strftime('%Y', c.first_purchase_date)) * 12 +\n",
    "        (strftime('%m', s.sale_date) - strftime('%m', c.first_purchase_date)) as months_since_first\n",
    "    FROM sales s\n",
    "    JOIN customer_cohorts c ON s.customer_id = c.customer_id\n",
    "),\n",
    "-- Step 3: Count unique customers per cohort\n",
    "cohort_sizes AS (\n",
    "    SELECT \n",
    "        cohort_month,\n",
    "        COUNT(DISTINCT customer_id) as cohort_size\n",
    "    FROM customer_cohorts\n",
    "    GROUP BY cohort_month\n",
    "),\n",
    "-- Step 4: Calculate retention\n",
    "retention_data AS (\n",
    "    SELECT \n",
    "        cp.cohort_month,\n",
    "        cp.months_since_first,\n",
    "        COUNT(DISTINCT cp.customer_id) as retained_customers\n",
    "    FROM customer_purchases cp\n",
    "    GROUP BY cp.cohort_month, cp.months_since_first\n",
    ")\n",
    "-- Final: Calculate retention rates\n",
    "SELECT \n",
    "    r.cohort_month,\n",
    "    r.months_since_first,\n",
    "    r.retained_customers,\n",
    "    c.cohort_size,\n",
    "    ROUND(r.retained_customers * 100.0 / c.cohort_size, 2) as retention_rate\n",
    "FROM retention_data r\n",
    "JOIN cohort_sizes c ON r.cohort_month = c.cohort_month\n",
    "WHERE r.cohort_month >= '2022-01' \n",
    "  AND r.cohort_month <= '2022-06'\n",
    "  AND r.months_since_first <= 12\n",
    "ORDER BY r.cohort_month, r.months_since_first\n",
    "\"\"\"\n",
    "\n",
    "show_sql(cohort_query, \"Complex Cohort Analysis with CTEs\")\n",
    "cohort_result = run_query(cohort_query, conn, \"Cohort retention analysis:\")\n",
    "\n",
    "# Visualize cohort retention\n",
    "if len(cohort_result) > 0:\n",
    "    pivot_cohort = cohort_result.pivot(index='cohort_month', \n",
    "                                       columns='months_since_first', \n",
    "                                       values='retention_rate')\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.heatmap(pivot_cohort, annot=True, fmt='.1f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Retention Rate (%)'})\n",
    "    plt.title('Cohort Retention Analysis')\n",
    "    plt.xlabel('Months Since First Purchase')\n",
    "    plt.ylabel('Cohort Month')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üå≥ Part 3: Recursive CTEs - Hierarchical Data\n",
    "\n",
    "Recursive CTEs are perfect for organizational charts and category trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee hierarchy using recursive CTE\n",
    "hierarchy_query = \"\"\"\n",
    "WITH RECURSIVE employee_hierarchy AS (\n",
    "    -- Anchor: Start with the CEO\n",
    "    SELECT \n",
    "        employee_id,\n",
    "        employee_name,\n",
    "        manager_id,\n",
    "        department,\n",
    "        salary,\n",
    "        0 as level,\n",
    "        employee_name as path\n",
    "    FROM employees\n",
    "    WHERE manager_id IS NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- Recursive: Add subordinates\n",
    "    SELECT \n",
    "        e.employee_id,\n",
    "        e.employee_name,\n",
    "        e.manager_id,\n",
    "        e.department,\n",
    "        e.salary,\n",
    "        h.level + 1,\n",
    "        h.path || ' > ' || e.employee_name\n",
    "    FROM employees e\n",
    "    INNER JOIN employee_hierarchy h ON e.manager_id = h.employee_id\n",
    ")\n",
    "SELECT \n",
    "    level,\n",
    "    substr('    ', 1, level * 2) || employee_name as org_chart,\n",
    "    department,\n",
    "    salary,\n",
    "    path\n",
    "FROM employee_hierarchy\n",
    "ORDER BY path\n",
    "\"\"\"\n",
    "\n",
    "show_sql(hierarchy_query, \"Recursive CTE for Employee Hierarchy\")\n",
    "hierarchy_result = run_query(hierarchy_query, conn, \"Organization Chart:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Part 4: PIVOT Operations\n",
    "\n",
    "Transform rows to columns for different analytical views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual PIVOT using CASE statements\n",
    "pivot_query = \"\"\"\n",
    "WITH monthly_category_sales AS (\n",
    "    SELECT \n",
    "        strftime('%Y-%m', s.sale_date) as month,\n",
    "        p.category,\n",
    "        SUM(s.revenue) as revenue\n",
    "    FROM sales s\n",
    "    JOIN products p ON s.product_id = p.product_id\n",
    "    WHERE s.sale_date >= '2024-01-01' \n",
    "      AND s.sale_date <= '2024-06-30'\n",
    "    GROUP BY strftime('%Y-%m', s.sale_date), p.category\n",
    ")\n",
    "SELECT \n",
    "    month,\n",
    "    SUM(CASE WHEN category = 'Electronics' THEN revenue ELSE 0 END) as Electronics,\n",
    "    SUM(CASE WHEN category = 'Clothing' THEN revenue ELSE 0 END) as Clothing,\n",
    "    SUM(CASE WHEN category = 'Books' THEN revenue ELSE 0 END) as Books,\n",
    "    SUM(CASE WHEN category = 'Home' THEN revenue ELSE 0 END) as Home,\n",
    "    SUM(CASE WHEN category = 'Sports' THEN revenue ELSE 0 END) as Sports,\n",
    "    SUM(revenue) as Total\n",
    "FROM monthly_category_sales\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "\n",
    "show_sql(pivot_query, \"PIVOT: Monthly Sales by Category\")\n",
    "pivot_result = run_query(pivot_query, conn, \"Pivoted sales data:\")\n",
    "\n",
    "# Visualize pivoted data\n",
    "if len(pivot_result) > 0:\n",
    "    pivot_result.set_index('month')[['Electronics', 'Clothing', 'Books', 'Home', 'Sports']].plot(\n",
    "        kind='bar', stacked=True, figsize=(12, 6), colormap='Set3'\n",
    "    )\n",
    "    plt.title('Monthly Sales by Category (Stacked)')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Revenue')\n",
    "    plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Part 5: Advanced Analytical Patterns\n",
    "\n",
    "Let's combine everything for complex real-world analytics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 RFM Analysis (Recency, Frequency, Monetary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM Analysis for Customer Segmentation\n",
    "rfm_query = \"\"\"\n",
    "WITH customer_rfm AS (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.customer_name,\n",
    "        c.customer_segment,\n",
    "        -- Recency: Days since last purchase\n",
    "        JULIANDAY('2024-12-31') - JULIANDAY(MAX(s.sale_date)) as recency,\n",
    "        -- Frequency: Number of purchases\n",
    "        COUNT(DISTINCT s.sale_id) as frequency,\n",
    "        -- Monetary: Total spend\n",
    "        COALESCE(SUM(s.revenue), 0) as monetary\n",
    "    FROM customers c\n",
    "    LEFT JOIN sales s ON c.customer_id = s.customer_id\n",
    "    GROUP BY c.customer_id, c.customer_name, c.customer_segment\n",
    "),\n",
    "rfm_scores AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        -- Score each dimension 1-5 (5 is best)\n",
    "        NTILE(5) OVER (ORDER BY recency DESC) as r_score,\n",
    "        NTILE(5) OVER (ORDER BY frequency) as f_score,\n",
    "        NTILE(5) OVER (ORDER BY monetary) as m_score\n",
    "    FROM customer_rfm\n",
    "    WHERE frequency > 0\n",
    ")\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    customer_segment,\n",
    "    ROUND(recency, 0) as recency_days,\n",
    "    frequency,\n",
    "    ROUND(monetary, 2) as monetary,\n",
    "    r_score,\n",
    "    f_score,\n",
    "    m_score,\n",
    "    r_score || f_score || m_score as rfm_combined,\n",
    "    CASE \n",
    "        WHEN r_score >= 4 AND f_score >= 4 AND m_score >= 4 THEN 'Champions'\n",
    "        WHEN r_score >= 3 AND f_score >= 3 AND m_score >= 4 THEN 'Loyal Customers'\n",
    "        WHEN r_score >= 3 AND f_score <= 2 AND m_score >= 3 THEN 'Potential Loyalists'\n",
    "        WHEN r_score >= 4 AND f_score <= 2 AND m_score <= 2 THEN 'New Customers'\n",
    "        WHEN r_score <= 2 AND f_score >= 3 AND m_score >= 3 THEN 'At Risk'\n",
    "        WHEN r_score <= 2 AND f_score <= 2 AND m_score >= 3 THEN 'Cant Lose Them'\n",
    "        ELSE 'Others'\n",
    "    END as rfm_segment\n",
    "FROM rfm_scores\n",
    "ORDER BY monetary DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "show_sql(rfm_query, \"RFM Analysis for Customer Segmentation\")\n",
    "rfm_result = run_query(rfm_query, conn, \"RFM Customer Segmentation:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Practice Exercises\n",
    "\n",
    "Now it's your turn! Try these advanced SQL challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Funnel Analysis\n",
    "\n",
    "Create a conversion funnel showing customer progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a funnel analysis\n",
    "# Stages: All customers -> Made 1 purchase -> Made 2+ purchases -> Made 5+ purchases\n",
    "\n",
    "print(\"Exercise: Create a funnel analysis\")\n",
    "print(\"Hint: Use CTEs to calculate each stage\")\n",
    "print(\"Hint: Calculate conversion rates between stages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Pareto Analysis (80/20 Rule)\n",
    "\n",
    "Find what percentage of customers generate 80% of revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Pareto analysis\n",
    "print(\"Exercise: Implement Pareto analysis\")\n",
    "print(\"Hint: Use cumulative sum window function\")\n",
    "print(\"Hint: Find where cumulative revenue reaches 80%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "1. **Window Functions**:\n",
    "   - Calculate across rows without grouping\n",
    "   - Essential for rankings, running totals, comparisons\n",
    "   - PARTITION BY creates windows, ORDER BY defines sequence\n",
    "\n",
    "2. **CTEs (Common Table Expressions)**:\n",
    "   - Break complex queries into readable steps\n",
    "   - Reusable within the same query\n",
    "   - Better than nested subqueries for clarity\n",
    "\n",
    "3. **Recursive CTEs**:\n",
    "   - Perfect for hierarchical data\n",
    "   - Self-referencing for tree traversal\n",
    "   - Use anchor + recursive members\n",
    "\n",
    "4. **PIVOT Operations**:\n",
    "   - Transform rows to columns\n",
    "   - Use CASE statements for manual pivot\n",
    "   - Essential for reporting formats\n",
    "\n",
    "5. **Advanced Patterns**:\n",
    "   - RFM for customer segmentation\n",
    "   - Cohort analysis for retention\n",
    "   - Time series decomposition\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "In the next notebook:\n",
    "- Query optimization and performance tuning\n",
    "- Cloud data warehouse features\n",
    "- Production SQL best practices\n",
    "\n",
    "Remember: **Advanced SQL transforms data into insights!** üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "conn.close()\n",
    "print(\"‚úÖ Database connection closed. Excellent work mastering advanced SQL!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
